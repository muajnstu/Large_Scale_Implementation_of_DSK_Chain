{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muajnstu/Large_Scale_Implementation_of_DSK_Chain/blob/main/Downstram_Pipeline_of_Proposed_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC9I-K0know3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.metrics import (accuracy_score, confusion_matrix, roc_auc_score, f1_score)\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, f1_score, roc_auc_score, recall_score, precision_score)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import neighbors\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    ExtraTreesClassifier,\n",
        "    BaggingClassifier\n",
        ")\n",
        "from sklearn.linear_model import (\n",
        "    LogisticRegression,\n",
        "    RidgeClassifier,\n",
        "    Perceptron,\n",
        "    SGDClassifier,\n",
        "    PassiveAggressiveClassifier\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/muajnstu/Large_Scale_Implementation_of_DSK_Chain/refs/heads/main/filtered%20data/SCE_data_fraudulent.csv')\n",
        "\n",
        "X = df.drop(columns=['Is Fraudulent'])\n",
        "y = df['Is Fraudulent']"
      ],
      "metadata": {
        "id": "QD3jmkd5-qXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/muajnstu/Large_Scale_Implementation_of_DSK_Chain/refs/heads/main/filtered%20data/Clustered_EmployeeAttrition.csv')\n",
        "\n",
        "X = df.drop(columns=['Attrition'])\n",
        "y = df['Attrition']"
      ],
      "metadata": {
        "id": "Qrqb_Qndn0l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.astype(str)"
      ],
      "metadata": {
        "id": "93ZMqML48z7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat = pd.Categorical(y)\n",
        "y_codes = y_cat.codes\n",
        "original_labels = y_cat.categories"
      ],
      "metadata": {
        "id": "JGHosBqI9C6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y_codes)\n",
        "print(\"Class distribution after SMOTE:\", pd.Series(y_resampled).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtyJaA-H9HZR",
        "outputId": "2c2c58f9-9d6c-4746-f054-ed7726b2127f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after SMOTE: 1    7985\n",
            "3    7985\n",
            "0    7985\n",
            "2    7985\n",
            "4    7985\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_resampled_labels = [original_labels[i] for i in y_resampled]"
      ],
      "metadata": {
        "id": "XkZN0DU19QUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled_labels, test_size=0.2, random_state=46, stratify=y_resampled_labels\n",
        ")"
      ],
      "metadata": {
        "id": "A1mfc-e99YDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(y_true, y_pred, y_prob=None):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    num_classes = cm.shape[0]\n",
        "\n",
        "    if num_classes == 2:\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        gmean = np.sqrt(specificity * sensitivity)\n",
        "        type1 = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
        "        type2 = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        fmeasure = f1_score(y_true, y_pred, pos_label=1)\n",
        "        auc = 0\n",
        "        if y_prob is not None and hasattr(y_prob, \"shape\") and y_prob.shape[1] > 1:\n",
        "            try:\n",
        "                auc = roc_auc_score(y_true, y_prob[:, 1])\n",
        "            except Exception:\n",
        "                auc = 0\n",
        "    else:\n",
        "        TP = np.diag(cm)\n",
        "        FP = np.sum(cm, axis=0) - TP\n",
        "        FN = np.sum(cm, axis=1) - TP\n",
        "        TN = np.sum(cm) - (FP + FN + TP)\n",
        "\n",
        "        specificity = np.mean([\n",
        "            TN[i] / (TN[i] + FP[i]) if (TN[i] + FP[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        sensitivity = np.mean([\n",
        "            TP[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        gmean = np.sqrt(specificity * sensitivity)\n",
        "        type1 = np.mean([\n",
        "            FP[i] / (FP[i] + TN[i]) if (FP[i] + TN[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        type2 = np.mean([\n",
        "            FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        fmeasure = f1_score(y_true, y_pred, average='macro')\n",
        "        auc = 0\n",
        "        if y_prob is not None and hasattr(y_prob, \"shape\") and y_prob.shape[1] > 1:\n",
        "            try:\n",
        "                auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
        "            except Exception:\n",
        "                auc = 0\n",
        "\n",
        "    print(f\"Accuracy      : {accuracy:.4f}\")\n",
        "    print(f\"Sensitivity   : {sensitivity:.4f}\")\n",
        "    print(f\"Specificity   : {specificity:.4f}\")\n",
        "    print(f\"G-Mean        : {gmean:.4f}\")\n",
        "    print(f\"Type I Error  : {type1:.4f}\")\n",
        "    print(f\"Type II Error : {type2:.4f}\")\n",
        "    print(f\"F1 Score      : {fmeasure:.4f}\")\n",
        "    print(f\"AUROC         : {auc:.4f}\")"
      ],
      "metadata": {
        "id": "KV6HvZf-w2TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(name, model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    try:\n",
        "        y_prob = model.predict_proba(X_test)\n",
        "    except Exception:\n",
        "        y_prob = None\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print_metrics(y_test, y_pred, y_prob)"
      ],
      "metadata": {
        "id": "J1U2oQAUw4iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ml_models = {\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(random_state=42),\n",
        "    \"Bagging\": BaggingClassifier(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"RidgeClassifier\": RidgeClassifier(random_state=42),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"NaiveBayes\": GaussianNB(),\n",
        "    \"Perceptron\": Perceptron(random_state=42),\n",
        "    \"SGDClassifier\": SGDClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"PassiveAggressive\": PassiveAggressiveClassifier(random_state=42),\n",
        "    #\"LinearSVM\": SVC(kernel='linear', probability=True, random_state=42),\n",
        "    \"RBFSVM\": SVC(kernel='rbf', probability=True, random_state=42),\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "    #\"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(verbosity=-1, random_state=42)\n",
        "}\n"
      ],
      "metadata": {
        "id": "Fqvh12sow8oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in ml_models.items():\n",
        "    run_model(name, model, X_resampled, X_test, y_resampled_labels, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pe3GFC4w_8H",
        "outputId": "f3e9ed5e-fe38-42e3-a57c-8371969c32db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: RandomForest\n",
            "Accuracy      : 1.0000\n",
            "Sensitivity   : 1.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 1.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 0.0000\n",
            "F1 Score      : 1.0000\n",
            "AUROC         : 1.0000\n",
            "\n",
            "Model: ExtraTrees\n",
            "Accuracy      : 1.0000\n",
            "Sensitivity   : 1.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 1.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 0.0000\n",
            "F1 Score      : 1.0000\n",
            "AUROC         : 1.0000\n",
            "\n",
            "Model: Bagging\n",
            "Accuracy      : 0.9670\n",
            "Sensitivity   : 0.9672\n",
            "Specificity   : 0.9934\n",
            "G-Mean        : 0.9802\n",
            "Type I Error  : 0.0066\n",
            "Type II Error : 0.0328\n",
            "F1 Score      : 0.9670\n",
            "AUROC         : 0.9992\n",
            "\n",
            "Model: GradientBoosting\n",
            "Accuracy      : 0.9764\n",
            "Sensitivity   : 0.9765\n",
            "Specificity   : 0.9953\n",
            "G-Mean        : 0.9858\n",
            "Type I Error  : 0.0047\n",
            "Type II Error : 0.0235\n",
            "F1 Score      : 0.9764\n",
            "AUROC         : 0.9999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: LogisticRegression\n",
            "Accuracy      : 0.4340\n",
            "Sensitivity   : 0.4345\n",
            "Specificity   : 0.8868\n",
            "G-Mean        : 0.6207\n",
            "Type I Error  : 0.1132\n",
            "Type II Error : 0.5655\n",
            "F1 Score      : 0.4378\n",
            "AUROC         : 0.8527\n",
            "\n",
            "Model: RidgeClassifier\n",
            "Accuracy      : 0.3915\n",
            "Sensitivity   : 0.3931\n",
            "Specificity   : 0.8784\n",
            "G-Mean        : 0.5876\n",
            "Type I Error  : 0.1216\n",
            "Type II Error : 0.6069\n",
            "F1 Score      : 0.3296\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: DecisionTree\n",
            "Accuracy      : 1.0000\n",
            "Sensitivity   : 1.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 1.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 0.0000\n",
            "F1 Score      : 1.0000\n",
            "AUROC         : 1.0000\n",
            "\n",
            "Model: NaiveBayes\n",
            "Accuracy      : 0.5755\n",
            "Sensitivity   : 0.5759\n",
            "Specificity   : 0.9151\n",
            "G-Mean        : 0.7260\n",
            "Type I Error  : 0.0849\n",
            "Type II Error : 0.4241\n",
            "F1 Score      : 0.5757\n",
            "AUROC         : 0.9253\n",
            "\n",
            "Model: Perceptron\n",
            "Accuracy      : 0.1651\n",
            "Sensitivity   : 0.1667\n",
            "Specificity   : 0.8333\n",
            "G-Mean        : 0.3727\n",
            "Type I Error  : 0.1667\n",
            "Type II Error : 0.8333\n",
            "F1 Score      : 0.0472\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: SGDClassifier\n",
            "Accuracy      : 0.1698\n",
            "Sensitivity   : 0.1667\n",
            "Specificity   : 0.8333\n",
            "G-Mean        : 0.3727\n",
            "Type I Error  : 0.1667\n",
            "Type II Error : 0.8333\n",
            "F1 Score      : 0.0484\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: KNN\n",
            "Accuracy      : 0.8208\n",
            "Sensitivity   : 0.8210\n",
            "Specificity   : 0.9642\n",
            "G-Mean        : 0.8897\n",
            "Type I Error  : 0.0358\n",
            "Type II Error : 0.1790\n",
            "F1 Score      : 0.8209\n",
            "AUROC         : 0.9745\n",
            "\n",
            "Model: PassiveAggressive\n",
            "Accuracy      : 0.1651\n",
            "Sensitivity   : 0.1667\n",
            "Specificity   : 0.8333\n",
            "G-Mean        : 0.3727\n",
            "Type I Error  : 0.1667\n",
            "Type II Error : 0.8333\n",
            "F1 Score      : 0.0472\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: RBFSVM\n",
            "Accuracy      : 0.5472\n",
            "Sensitivity   : 0.5470\n",
            "Specificity   : 0.9094\n",
            "G-Mean        : 0.7053\n",
            "Type I Error  : 0.0906\n",
            "Type II Error : 0.4530\n",
            "F1 Score      : 0.5439\n",
            "AUROC         : 0.9089\n",
            "\n",
            "Model: LDA\n",
            "Accuracy      : 0.5613\n",
            "Sensitivity   : 0.5614\n",
            "Specificity   : 0.9122\n",
            "G-Mean        : 0.7156\n",
            "Type I Error  : 0.0878\n",
            "Type II Error : 0.4386\n",
            "F1 Score      : 0.5618\n",
            "AUROC         : 0.9226\n",
            "\n",
            "Model: QDA\n",
            "Accuracy      : 0.6604\n",
            "Sensitivity   : 0.6607\n",
            "Specificity   : 0.9321\n",
            "G-Mean        : 0.7847\n",
            "Type I Error  : 0.0679\n",
            "Type II Error : 0.3393\n",
            "F1 Score      : 0.6612\n",
            "AUROC         : 0.9420\n",
            "\n",
            "Model: LightGBM\n",
            "Accuracy      : 1.0000\n",
            "Sensitivity   : 1.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 1.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 0.0000\n",
            "F1 Score      : 1.0000\n",
            "AUROC         : 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate all models\n",
        "for name, model in ml_models.items():\n",
        "    run_model(name, model, X_resampled, X_test, y_resampled_labels, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfTOVMhV_K70",
        "outputId": "126eadd1-751b-4d43-d152-cd25d5f1f2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: RandomForest\n",
            "Accuracy      : 1.0000\n",
            "Sensitivity   : 1.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 1.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 0.0000\n",
            "F1 Score      : 1.0000\n",
            "AUROC         : 1.0000\n",
            "\n",
            "Model: ExtraTrees\n",
            "Accuracy      : 1.0000\n",
            "Sensitivity   : 1.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 1.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 0.0000\n",
            "F1 Score      : 1.0000\n",
            "AUROC         : 1.0000\n",
            "\n",
            "Model: Bagging\n",
            "Accuracy      : 0.9955\n",
            "Sensitivity   : 0.9955\n",
            "Specificity   : 0.9989\n",
            "G-Mean        : 0.9972\n",
            "Type I Error  : 0.0011\n",
            "Type II Error : 0.0045\n",
            "F1 Score      : 0.9955\n",
            "AUROC         : 1.0000\n",
            "\n",
            "Model: GradientBoosting\n",
            "Accuracy      : 0.9260\n",
            "Sensitivity   : 0.9260\n",
            "Specificity   : 0.9815\n",
            "G-Mean        : 0.9533\n",
            "Type I Error  : 0.0185\n",
            "Type II Error : 0.0740\n",
            "F1 Score      : 0.9221\n",
            "AUROC         : 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: LogisticRegression\n",
            "Accuracy      : 0.7966\n",
            "Sensitivity   : 0.7966\n",
            "Specificity   : 0.9492\n",
            "G-Mean        : 0.8695\n",
            "Type I Error  : 0.0508\n",
            "Type II Error : 0.2034\n",
            "F1 Score      : 0.7905\n",
            "AUROC         : 0.9410\n",
            "\n",
            "Model: RidgeClassifier\n",
            "Accuracy      : 0.7100\n",
            "Sensitivity   : 0.7100\n",
            "Specificity   : 0.9275\n",
            "G-Mean        : 0.8115\n",
            "Type I Error  : 0.0725\n",
            "Type II Error : 0.2900\n",
            "F1 Score      : 0.6268\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: DecisionTree\n",
            "Accuracy      : 1.0000\n",
            "Sensitivity   : 1.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 1.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 0.0000\n",
            "F1 Score      : 1.0000\n",
            "AUROC         : 1.0000\n",
            "\n",
            "Model: NaiveBayes\n",
            "Accuracy      : 0.8288\n",
            "Sensitivity   : 0.8288\n",
            "Specificity   : 0.9572\n",
            "G-Mean        : 0.8907\n",
            "Type I Error  : 0.0428\n",
            "Type II Error : 0.1712\n",
            "F1 Score      : 0.8250\n",
            "AUROC         : 0.9555\n",
            "\n",
            "Model: Perceptron\n",
            "Accuracy      : 0.3348\n",
            "Sensitivity   : 0.3348\n",
            "Specificity   : 0.8337\n",
            "G-Mean        : 0.5283\n",
            "Type I Error  : 0.1663\n",
            "Type II Error : 0.6652\n",
            "F1 Score      : 0.2658\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: SGDClassifier\n",
            "Accuracy      : 0.7098\n",
            "Sensitivity   : 0.7098\n",
            "Specificity   : 0.9275\n",
            "G-Mean        : 0.8114\n",
            "Type I Error  : 0.0725\n",
            "Type II Error : 0.2902\n",
            "F1 Score      : 0.7076\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: KNN\n",
            "Accuracy      : 0.9637\n",
            "Sensitivity   : 0.9637\n",
            "Specificity   : 0.9909\n",
            "G-Mean        : 0.9772\n",
            "Type I Error  : 0.0091\n",
            "Type II Error : 0.0363\n",
            "F1 Score      : 0.9641\n",
            "AUROC         : 0.9989\n",
            "\n",
            "Model: PassiveAggressive\n",
            "Accuracy      : 0.5726\n",
            "Sensitivity   : 0.5726\n",
            "Specificity   : 0.8931\n",
            "G-Mean        : 0.7151\n",
            "Type I Error  : 0.1069\n",
            "Type II Error : 0.4274\n",
            "F1 Score      : 0.4853\n",
            "AUROC         : 0.0000\n",
            "\n",
            "Model: RBFSVM\n",
            "Accuracy      : 0.8258\n",
            "Sensitivity   : 0.8258\n",
            "Specificity   : 0.9564\n",
            "G-Mean        : 0.8887\n",
            "Type I Error  : 0.0436\n",
            "Type II Error : 0.1742\n",
            "F1 Score      : 0.8028\n",
            "AUROC         : 0.9407\n",
            "\n",
            "Model: LDA\n",
            "Accuracy      : 0.8078\n",
            "Sensitivity   : 0.8078\n",
            "Specificity   : 0.9519\n",
            "G-Mean        : 0.8769\n",
            "Type I Error  : 0.0481\n",
            "Type II Error : 0.1922\n",
            "F1 Score      : 0.7970\n",
            "AUROC         : 0.9483\n",
            "\n",
            "Model: QDA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy      : 0.5068\n",
            "Sensitivity   : 0.5068\n",
            "Specificity   : 0.8767\n",
            "G-Mean        : 0.6666\n",
            "Type I Error  : 0.1233\n",
            "Type II Error : 0.4932\n",
            "F1 Score      : 0.4150\n",
            "AUROC         : 0.8142\n",
            "\n",
            "Model: LightGBM\n",
            "Accuracy      : 0.9733\n",
            "Sensitivity   : 0.9733\n",
            "Specificity   : 0.9933\n",
            "G-Mean        : 0.9833\n",
            "Type I Error  : 0.0067\n",
            "Type II Error : 0.0267\n",
            "F1 Score      : 0.9729\n",
            "AUROC         : 0.9992\n"
          ]
        }
      ]
    }
  ]
}